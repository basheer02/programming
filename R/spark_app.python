from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Create a Spark session
spark = SparkSession.builder \
    .appName("SimplePySparkProgram") \
    .getOrCreate()

# Load data from a CSV file
data_path = "path/to/your/file.csv"
data_df = spark.read.csv(data_path, header=True, inferSchema=True)

# Perform some basic transformations
transformed_df = data_df.select("Name", "Age", "City") \
    .filter(col("Age") > 25) \
    .orderBy(col("Age"), ascending=False)

# Show the transformed DataFrame
transformed_df.show()

# Stop the Spark session
spark.stop()
